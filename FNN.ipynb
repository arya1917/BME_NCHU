{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "### Load Dataset\n",
    "data = pd.read_csv('/kaggle/input/modeldata/data1.csv')\n",
    "\n",
    "### Preprocessing\n",
    "# Separate features and labels\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "### Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "### Reshape for GRU Input\n",
    "# GRU requires 3D input: (samples, timesteps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "### Build and Evaluate Multiple GRU Models with Different Hyperparameters\n",
    "def build_and_evaluate_model(learning_rate, layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add GRU layers\n",
    "    for i, units in enumerate(layers):\n",
    "        if i == 0:\n",
    "            model.add(GRU(units, activation='tanh', return_sequences=(i != len(layers) - 1), input_shape=(1, X_train.shape[2])))\n",
    "        else:\n",
    "            model.add(GRU(units, activation='tanh', return_sequences=(i != len(layers) - 1)))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "    # Add Dense layers\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(len(np.unique(y)), activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy with learning_rate={learning_rate} and layers={layers}: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "### Experiment with Different Configurations\n",
    "learning_rates = [0.001, 0.0005, 0.0001]\n",
    "layer_configurations = [[128, 64], [256, 128, 64], [128, 128, 64, 32]]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_config = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for layers in layer_configurations:\n",
    "        print(f\"Evaluating model with learning_rate={lr} and layers={layers}...\")\n",
    "        accuracy = build_and_evaluate_model(lr, layers)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_config = (lr, layers)\n",
    "\n",
    "print(f\"Best Accuracy: {best_accuracy * 100:.2f}% with learning_rate={best_config[0]} and layers={best_config[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Frequency         Z     Deg       Z.1   Deg.1       Z.2   Deg.2  \\\n",
      "0      10.000000   85042.0 -76.231   89189.0 -77.743   90240.0 -77.253   \n",
      "1  378314.728446  138389.0 -14.992  132932.0 -15.101  130529.0 -15.183   \n",
      "2  366799.267633  138709.0 -15.037  133246.0 -15.163  130821.0 -15.254   \n",
      "3  355634.324069  139043.0 -15.088  133551.0 -15.234  131141.0 -15.332   \n",
      "4  344809.228416  139379.0 -15.154  133867.0 -15.314  131457.0 -15.421   \n",
      "\n",
      "          Z_mean  Z_median  Z_weighted_avg  Z_geometric_mean  Z_harmonic_mean  \\\n",
      "0   88157.000000   89189.0    88214.122097      88128.142301     88098.997497   \n",
      "1  133950.000000  132932.0   134030.737305     133909.906545    133870.100205   \n",
      "2  134258.666667  133246.0   134339.725401     134218.411726    134178.443200   \n",
      "3  134578.333333  133551.0   134659.584458     134537.985845    134497.928443   \n",
      "4  134901.000000  133867.0   134982.498719     134860.530591    134820.353189   \n",
      "\n",
      "    Deg_mean  Deg_median  Deg_weighted_avg    label  \n",
      "0 -77.075667     -77.253        -77.080814  AB_10-3  \n",
      "1 -15.092000     -15.101        -15.092406  AB_10-3  \n",
      "2 -15.151333     -15.163        -15.151856  AB_10-3  \n",
      "3 -15.218000     -15.234        -15.218660  AB_10-3  \n",
      "4 -15.296333     -15.314        -15.297120  AB_10-3  \n",
      "Training model with layers [128, 64] and learning rate 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0067 - loss: -615092992.0000 - val_accuracy: 0.0076 - val_loss: -9377690624.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0065 - loss: -18390005760.0000 - val_accuracy: 0.0076 - val_loss: -59433259008.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0061 - loss: -80922615808.0000 - val_accuracy: 0.0076 - val_loss: -164024090624.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0058 - loss: -201651421184.0000 - val_accuracy: 0.0076 - val_loss: -331696078848.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0064 - loss: -385831010304.0000 - val_accuracy: 0.0076 - val_loss: -572631810048.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0063 - loss: -648411938816.0000 - val_accuracy: 0.0076 - val_loss: -896983105536.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0067 - loss: -987791818752.0000 - val_accuracy: 0.0076 - val_loss: -1313845280768.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0062 - loss: -1441883881472.0000 - val_accuracy: 0.0076 - val_loss: -1831541145600.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0074 - loss: -1977168822272.0000 - val_accuracy: 0.0076 - val_loss: -2461249044480.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0069 - loss: -2643994345472.0000 - val_accuracy: 0.0076 - val_loss: -3208838643712.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0060 - loss: -3408961994752.0000 - val_accuracy: 0.0076 - val_loss: -4087789649920.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0061 - loss: -4342564257792.0000 - val_accuracy: 0.0076 - val_loss: -5105529651200.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0067 - loss: -5420870008832.0000 - val_accuracy: 0.0076 - val_loss: -6269448486912.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0062 - loss: -6578685083648.0000 - val_accuracy: 0.0076 - val_loss: -7591521943552.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0059 - loss: -7960185012224.0000 - val_accuracy: 0.0076 - val_loss: -9078078177280.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0067 - loss: -9501579149312.0000 - val_accuracy: 0.0076 - val_loss: -10740973961216.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.0066 - loss: -11152395337728.0000 - val_accuracy: 0.0076 - val_loss: -12591347793920.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0062 - loss: -13084388229120.0000 - val_accuracy: 0.0076 - val_loss: -14628715233280.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0067 - loss: -15092844331008.0000 - val_accuracy: 0.0076 - val_loss: -16872705622016.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.0063 - loss: -17531505999872.0000 - val_accuracy: 0.0076 - val_loss: -19323483586560.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0065 - loss: -19928818122752.0000 - val_accuracy: 0.0076 - val_loss: -21993999040512.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0060 - loss: -22691413229568.0000 - val_accuracy: 0.0076 - val_loss: -24892240035840.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0064 - loss: -25639706951680.0000 - val_accuracy: 0.0076 - val_loss: -28030581866496.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0060 - loss: -28916578254848.0000 - val_accuracy: 0.0076 - val_loss: -31413508243456.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0062 - loss: -32205459947520.0000 - val_accuracy: 0.0076 - val_loss: -35050708008960.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0061 - loss: -36122117799936.0000 - val_accuracy: 0.0076 - val_loss: -38951679164416.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0070 - loss: -39580640215040.0000 - val_accuracy: 0.0076 - val_loss: -43135950389248.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0068 - loss: -44237278150656.0000 - val_accuracy: 0.0076 - val_loss: -47580591423488.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0060 - loss: -48695777165312.0000 - val_accuracy: 0.0076 - val_loss: -52333908066304.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0059 - loss: -53653780037632.0000 - val_accuracy: 0.0076 - val_loss: -57360508780544.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0068 - loss: -58556569092096.0000 - val_accuracy: 0.0076 - val_loss: -62712528764928.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0065 - loss: -64639081644032.0000 - val_accuracy: 0.0076 - val_loss: -68374751084544.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0063 - loss: -70050337783808.0000 - val_accuracy: 0.0076 - val_loss: -74375562788864.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0063 - loss: -75935617384448.0000 - val_accuracy: 0.0076 - val_loss: -80699616919552.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0064 - loss: -81794170880000.0000 - val_accuracy: 0.0076 - val_loss: -87377594810368.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0064 - loss: -89033111764992.0000 - val_accuracy: 0.0076 - val_loss: -94392484364288.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0067 - loss: -95770220953600.0000 - val_accuracy: 0.0076 - val_loss: -101771816992768.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0068 - loss: -103876309024768.0000 - val_accuracy: 0.0076 - val_loss: -109508437213184.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0063 - loss: -111669585903616.0000 - val_accuracy: 0.0076 - val_loss: -117628702031872.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0064 - loss: -120079475802112.0000 - val_accuracy: 0.0076 - val_loss: -126146846916608.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.0059 - loss: -127072974405632.0000 - val_accuracy: 0.0076 - val_loss: -135044534370304.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0061 - loss: -137529005178880.0000 - val_accuracy: 0.0076 - val_loss: -144338113789952.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.0066 - loss: -147459531603968.0000 - val_accuracy: 0.0076 - val_loss: -154064352444416.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0067 - loss: -155422686183424.0000 - val_accuracy: 0.0076 - val_loss: -164211179126784.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0066 - loss: -167086978498560.0000 - val_accuracy: 0.0076 - val_loss: -174776580571136.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0076 - loss: -178406817792000.0000 - val_accuracy: 0.0076 - val_loss: -185790218895360.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0064 - loss: -188512288636928.0000 - val_accuracy: 0.0076 - val_loss: -197267210371072.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0065 - loss: -200776248983552.0000 - val_accuracy: 0.0076 - val_loss: -209174185115648.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0061 - loss: -211353730023424.0000 - val_accuracy: 0.0076 - val_loss: -221527115038720.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0072 - loss: -223323166343168.0000 - val_accuracy: 0.0076 - val_loss: -234398326718464.0000\n",
      "460/460 - 1s - 2ms/step - accuracy: 0.0076 - loss: -2.3509e+14\n",
      "Test Accuracy: 0.76%\n",
      "--------------------------------------------------\n",
      "Training model with layers [128, 64] and learning rate 0.001\n",
      "Epoch 1/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0063 - loss: -552208.4375 - val_accuracy: 0.0076 - val_loss: -8235160.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0063 - loss: -16058073.0000 - val_accuracy: 0.0076 - val_loss: -51510832.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0065 - loss: -70748184.0000 - val_accuracy: 0.0076 - val_loss: -142255328.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0066 - loss: -175353344.0000 - val_accuracy: 0.0076 - val_loss: -288311232.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0063 - loss: -337456000.0000 - val_accuracy: 0.0076 - val_loss: -497511200.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0060 - loss: -564166080.0000 - val_accuracy: 0.0076 - val_loss: -779350720.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.0067 - loss: -864316416.0000 - val_accuracy: 0.0076 - val_loss: -1142058752.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0065 - loss: -1249456128.0000 - val_accuracy: 0.0076 - val_loss: -1592510720.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.0060 - loss: -1727454720.0000 - val_accuracy: 0.0076 - val_loss: -2139893376.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0061 - loss: -2278344448.0000 - val_accuracy: 0.0076 - val_loss: -2791765248.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0060 - loss: -2973159424.0000 - val_accuracy: 0.0076 - val_loss: -3556281856.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0066 - loss: -3785106944.0000 - val_accuracy: 0.0076 - val_loss: -4443312128.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0063 - loss: -4707808768.0000 - val_accuracy: 0.0076 - val_loss: -5456175616.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0065 - loss: -5736823808.0000 - val_accuracy: 0.0076 - val_loss: -6607525888.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0063 - loss: -6916828672.0000 - val_accuracy: 0.0076 - val_loss: -7903060480.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0061 - loss: -8190784000.0000 - val_accuracy: 0.0076 - val_loss: -9351769088.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0062 - loss: -9722798080.0000 - val_accuracy: 0.0076 - val_loss: -10960492544.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0062 - loss: -11422949376.0000 - val_accuracy: 0.0076 - val_loss: -12739288064.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0066 - loss: -13242990592.0000 - val_accuracy: 0.0076 - val_loss: -14691889152.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0061 - loss: -15163061248.0000 - val_accuracy: 0.0076 - val_loss: -16826242048.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0058 - loss: -17323157504.0000 - val_accuracy: 0.0076 - val_loss: -19158863872.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0062 - loss: -19720912896.0000 - val_accuracy: 0.0076 - val_loss: -21683326976.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0060 - loss: -22334162944.0000 - val_accuracy: 0.0076 - val_loss: -24418187264.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0061 - loss: -25202386944.0000 - val_accuracy: 0.0076 - val_loss: -27368828928.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0066 - loss: -28165474304.0000 - val_accuracy: 0.0076 - val_loss: -30541799424.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0059 - loss: -31312836608.0000 - val_accuracy: 0.0076 - val_loss: -33938935808.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0063 - loss: -34705338368.0000 - val_accuracy: 0.0076 - val_loss: -37589659648.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0067 - loss: -38520741888.0000 - val_accuracy: 0.0076 - val_loss: -41471725568.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0068 - loss: -42473844736.0000 - val_accuracy: 0.0076 - val_loss: -45606363136.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0063 - loss: -46640246784.0000 - val_accuracy: 0.0076 - val_loss: -50008616960.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0059 - loss: -51310878720.0000 - val_accuracy: 0.0076 - val_loss: -54669008896.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0069 - loss: -55908204544.0000 - val_accuracy: 0.0076 - val_loss: -59605786624.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0059 - loss: -60491337728.0000 - val_accuracy: 0.0076 - val_loss: -64838205440.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0066 - loss: -66071814144.0000 - val_accuracy: 0.0076 - val_loss: -70363037696.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0060 - loss: -71758381056.0000 - val_accuracy: 0.0076 - val_loss: -76179202048.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0064 - loss: -78142791680.0000 - val_accuracy: 0.0076 - val_loss: -82291875840.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0063 - loss: -83456843776.0000 - val_accuracy: 0.0076 - val_loss: -88721195008.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0061 - loss: -90189733888.0000 - val_accuracy: 0.0076 - val_loss: -95486967808.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0064 - loss: -97241694208.0000 - val_accuracy: 0.0076 - val_loss: -102561275904.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0070 - loss: -105344270336.0000 - val_accuracy: 0.0076 - val_loss: -109973078016.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0060 - loss: -111924781056.0000 - val_accuracy: 0.0076 - val_loss: -117747892224.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0061 - loss: -120551391232.0000 - val_accuracy: 0.0076 - val_loss: -125862477824.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0064 - loss: -127611994112.0000 - val_accuracy: 0.0076 - val_loss: -134336929792.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0066 - loss: -137543876608.0000 - val_accuracy: 0.0076 - val_loss: -143172567040.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0059 - loss: -145466654720.0000 - val_accuracy: 0.0076 - val_loss: -152406245376.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0062 - loss: -154589003776.0000 - val_accuracy: 0.0076 - val_loss: -162001387520.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0070 - loss: -163829039104.0000 - val_accuracy: 0.0076 - val_loss: -172011012096.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0067 - loss: -174372438016.0000 - val_accuracy: 0.0076 - val_loss: -182413672448.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0064 - loss: -183777148928.0000 - val_accuracy: 0.0076 - val_loss: -193211580416.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.0066 - loss: -195641868288.0000 - val_accuracy: 0.0076 - val_loss: -204399493120.0000\n",
      "460/460 - 1s - 1ms/step - accuracy: 0.0076 - loss: -2.0509e+11\n",
      "Test Accuracy: 0.76%\n",
      "--------------------------------------------------\n",
      "Training model with layers [256, 128, 64] and learning rate 0.01\n",
      "Epoch 1/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0061 - loss: -2283812159488.0000 - val_accuracy: 0.0076 - val_loss: -54432544849920.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.0066 - loss: -141024898842624.0000 - val_accuracy: 0.0076 - val_loss: -633559215767552.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0071 - loss: -974773362360320.0000 - val_accuracy: 0.0076 - val_loss: -2402143533268992.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0061 - loss: -3169631908921344.0000 - val_accuracy: 0.0076 - val_loss: -6006623969476608.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0065 - loss: -7323251562774528.0000 - val_accuracy: 0.0076 - val_loss: -12125856612745216.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0069 - loss: -14298995174146048.0000 - val_accuracy: 0.0076 - val_loss: -21561188944969728.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0065 - loss: -24749076880818176.0000 - val_accuracy: 0.0076 - val_loss: -35176054884663296.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.0063 - loss: -39473987855581184.0000 - val_accuracy: 0.0076 - val_loss: -53941542242484224.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.0064 - loss: -59674395869708288.0000 - val_accuracy: 0.0076 - val_loss: -78808664151949312.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0056 - loss: -86860920378097664.0000 - val_accuracy: 0.0076 - val_loss: -110847857459724288.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0064 - loss: -120949766568804352.0000 - val_accuracy: 0.0076 - val_loss: -151342192105881600.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0068 - loss: -163233187021979648.0000 - val_accuracy: 0.0076 - val_loss: -201540154953826304.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0066 - loss: -216570255567224832.0000 - val_accuracy: 0.0076 - val_loss: -262755052513394688.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.0068 - loss: -278982607188787200.0000 - val_accuracy: 0.0076 - val_loss: -336090399321882624.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.0067 - loss: -357602309959581696.0000 - val_accuracy: 0.0076 - val_loss: -423328125770792960.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.0064 - loss: -446601591475142656.0000 - val_accuracy: 0.0076 - val_loss: -526001380565975040.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.0064 - loss: -552190819826663424.0000 - val_accuracy: 0.0076 - val_loss: -645600379920187392.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0066 - loss: -677239239326302208.0000 - val_accuracy: 0.0076 - val_loss: -783895303194411008.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0064 - loss: -825555798770843648.0000 - val_accuracy: 0.0076 - val_loss: -942091455650856960.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0066 - loss: -987330792856223744.0000 - val_accuracy: 0.0076 - val_loss: -1123056020017381376.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0069 - loss: -1164230394015383552.0000 - val_accuracy: 0.0076 - val_loss: -1328056527042379776.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0065 - loss: -1377592137213804544.0000 - val_accuracy: 0.0076 - val_loss: -1558994101049753600.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0060 - loss: -1616199492019683328.0000 - val_accuracy: 0.0076 - val_loss: -1818041651893895168.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0071 - loss: -1886173989420662784.0000 - val_accuracy: 0.0076 - val_loss: -2107151362469920768.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0065 - loss: -2184806020449042432.0000 - val_accuracy: 0.0076 - val_loss: -2429075722699014144.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.0057 - loss: -2525073258286415872.0000 - val_accuracy: 0.0076 - val_loss: -2784805942313615360.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.0064 - loss: -2876965907442171904.0000 - val_accuracy: 0.0076 - val_loss: -3177816752935403520.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0064 - loss: -3277547680254918656.0000 - val_accuracy: 0.0076 - val_loss: -3610515260395487232.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.0064 - loss: -3715629671522500608.0000 - val_accuracy: 0.0076 - val_loss: -4083978986089086976.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0064 - loss: -4179439960002134016.0000 - val_accuracy: 0.0076 - val_loss: -4603138415033057280.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.0067 - loss: -4730753232110878720.0000 - val_accuracy: 0.0076 - val_loss: -5169887181128335360.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0064 - loss: -5339763376887169024.0000 - val_accuracy: 0.0076 - val_loss: -5784335510415605760.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0059 - loss: -5898487357367123968.0000 - val_accuracy: 0.0076 - val_loss: -6452781405498769408.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0064 - loss: -6620760393943875584.0000 - val_accuracy: 0.0076 - val_loss: -7176346368238157824.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0063 - loss: -7339930608707043328.0000 - val_accuracy: 0.0076 - val_loss: -7956603799773118464.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0058 - loss: -8167187214527102976.0000 - val_accuracy: 0.0076 - val_loss: -8796165589975433216.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0066 - loss: -9004777030625001472.0000 - val_accuracy: 0.0076 - val_loss: -9704032341030076416.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0071 - loss: -9991546935112105984.0000 - val_accuracy: 0.0076 - val_loss: -10673277129682059264.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0070 - loss: -10974994115460071424.0000 - val_accuracy: 0.0076 - val_loss: -11716511354301972480.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0057 - loss: -12021181628312190976.0000 - val_accuracy: 0.0076 - val_loss: -12834172620517670912.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.0063 - loss: -13113642088019263488.0000 - val_accuracy: 0.0076 - val_loss: -14026004742119882752.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.0066 - loss: -14338359502896627712.0000 - val_accuracy: 0.0076 - val_loss: -15299658121014673408.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0071 - loss: -15560036768123191296.0000 - val_accuracy: 0.0076 - val_loss: -16656040953806585856.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0068 - loss: -17090383231150194688.0000 - val_accuracy: 0.0076 - val_loss: -18095443511565352960.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.0056 - loss: -18464494589428367360.0000 - val_accuracy: 0.0076 - val_loss: -19632798261707800576.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.0063 - loss: -19975779918876246016.0000 - val_accuracy: 0.0076 - val_loss: -21265018875094761472.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0065 - loss: -21634503160539119616.0000 - val_accuracy: 0.0076 - val_loss: -22987702907168620544.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0059 - loss: -23527470757429903360.0000 - val_accuracy: 0.0076 - val_loss: -24811601382625771520.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0060 - loss: -25336369695260934144.0000 - val_accuracy: 0.0076 - val_loss: -26744065636209524736.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0066 - loss: -27305212390561284096.0000 - val_accuracy: 0.0076 - val_loss: -28785012105036169216.0000\n",
      "460/460 - 1s - 3ms/step - accuracy: 0.0076 - loss: -2.8871e+19\n",
      "Test Accuracy: 0.76%\n",
      "--------------------------------------------------\n",
      "Training model with layers [256, 128, 64] and learning rate 0.001\n",
      "Epoch 1/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.0064 - loss: -358424416.0000 - val_accuracy: 0.0076 - val_loss: -8478873088.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.0062 - loss: -21752573952.0000 - val_accuracy: 0.0076 - val_loss: -96527687680.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0061 - loss: -148301578240.0000 - val_accuracy: 0.0076 - val_loss: -366755020800.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0058 - loss: -482023866368.0000 - val_accuracy: 0.0076 - val_loss: -924174581760.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0063 - loss: -1128584839168.0000 - val_accuracy: 0.0076 - val_loss: -1881309970432.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0062 - loss: -2208577617920.0000 - val_accuracy: 0.0076 - val_loss: -3373486047232.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.0059 - loss: -3859539558400.0000 - val_accuracy: 0.0076 - val_loss: -5554171805696.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0065 - loss: -6207158353920.0000 - val_accuracy: 0.0076 - val_loss: -8579952672768.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0064 - loss: -9481878503424.0000 - val_accuracy: 0.0076 - val_loss: -12621735526400.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0063 - loss: -13915505295360.0000 - val_accuracy: 0.0076 - val_loss: -17862322290688.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0058 - loss: -19365806211072.0000 - val_accuracy: 0.0076 - val_loss: -24515214049280.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0063 - loss: -26551424909312.0000 - val_accuracy: 0.0076 - val_loss: -32785318281216.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.0064 - loss: -35044573839360.0000 - val_accuracy: 0.0076 - val_loss: -42921638232064.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0058 - loss: -45988072914944.0000 - val_accuracy: 0.0076 - val_loss: -55105739030528.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0066 - loss: -58636118261760.0000 - val_accuracy: 0.0076 - val_loss: -69646866710528.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0062 - loss: -73689064275968.0000 - val_accuracy: 0.0076 - val_loss: -86738533875712.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0064 - loss: -90976173424640.0000 - val_accuracy: 0.0076 - val_loss: -106769254711296.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0060 - loss: -112611207151616.0000 - val_accuracy: 0.0076 - val_loss: -129963118297088.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0064 - loss: -135797781037056.0000 - val_accuracy: 0.0076 - val_loss: -156608902463488.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0063 - loss: -164081659019264.0000 - val_accuracy: 0.0076 - val_loss: -187085805846528.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0062 - loss: -195600813391872.0000 - val_accuracy: 0.0076 - val_loss: -221626251608064.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0064 - loss: -232464131817472.0000 - val_accuracy: 0.0076 - val_loss: -260658159419392.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0069 - loss: -270811797651456.0000 - val_accuracy: 0.0076 - val_loss: -304595590971392.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0061 - loss: -317759565070336.0000 - val_accuracy: 0.0076 - val_loss: -353623951278080.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0065 - loss: -369418190192640.0000 - val_accuracy: 0.0076 - val_loss: -408334184218624.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0062 - loss: -421499232059392.0000 - val_accuracy: 0.0076 - val_loss: -469004355371008.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0058 - loss: -485428276756480.0000 - val_accuracy: 0.0076 - val_loss: -536028326658048.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0057 - loss: -557052158017536.0000 - val_accuracy: 0.0076 - val_loss: -609670339231744.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0057 - loss: -627664373153792.0000 - val_accuracy: 0.0076 - val_loss: -690749523886080.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.0061 - loss: -712100947165184.0000 - val_accuracy: 0.0076 - val_loss: -779563541987328.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0062 - loss: -812840210399232.0000 - val_accuracy: 0.0076 - val_loss: -875974484819968.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0058 - loss: -898497628864512.0000 - val_accuracy: 0.0076 - val_loss: -981385934274560.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.0062 - loss: -1013271570153472.0000 - val_accuracy: 0.0076 - val_loss: -1095602402230272.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0062 - loss: -1122060877168640.0000 - val_accuracy: 0.0076 - val_loss: -1219662129922048.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0061 - loss: -1248940385107968.0000 - val_accuracy: 0.0076 - val_loss: -1353831673757696.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0063 - loss: -1390335271895040.0000 - val_accuracy: 0.0076 - val_loss: -1498206730977280.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0067 - loss: -1543129672974336.0000 - val_accuracy: 0.0076 - val_loss: -1653985463238656.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0059 - loss: -1695527729102848.0000 - val_accuracy: 0.0076 - val_loss: -1821593206521856.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0067 - loss: -1851236668145664.0000 - val_accuracy: 0.0076 - val_loss: -2001510191857664.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0066 - loss: -2036972663078912.0000 - val_accuracy: 0.0076 - val_loss: -2193941906587648.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.0067 - loss: -2233176567054336.0000 - val_accuracy: 0.0076 - val_loss: -2400140199460864.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.0066 - loss: -2460056872288256.0000 - val_accuracy: 0.0076 - val_loss: -2619938640494592.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0060 - loss: -2678089008021504.0000 - val_accuracy: 0.0076 - val_loss: -2854695378878464.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0062 - loss: -2914146584625152.0000 - val_accuracy: 0.0076 - val_loss: -3104488529330176.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0061 - loss: -3181542658539520.0000 - val_accuracy: 0.0076 - val_loss: -3370085548818432.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.0065 - loss: -3430713038733312.0000 - val_accuracy: 0.0076 - val_loss: -3652451194372096.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0058 - loss: -3725122041020416.0000 - val_accuracy: 0.0076 - val_loss: -3952414931550208.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0067 - loss: -4033800266842112.0000 - val_accuracy: 0.0076 - val_loss: -4269288491843584.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0061 - loss: -4370485437530112.0000 - val_accuracy: 0.0076 - val_loss: -4604843280826368.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0067 - loss: -4708771825713152.0000 - val_accuracy: 0.0076 - val_loss: -4960337723916288.0000\n",
      "460/460 - 1s - 2ms/step - accuracy: 0.0076 - loss: -4.9760e+15\n",
      "Test Accuracy: 0.76%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'corrected_data1.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(data.head())\n",
    "\n",
    "# Assuming 'label' is the target column and the rest are features\n",
    "X = data.drop(columns=['label'])\n",
    "y = data['label']\n",
    "\n",
    "# Encode labels to integers if they are categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define layer configurations and learning rates\n",
    "layer_configurations = [[128, 64], [256, 128, 64]]\n",
    "learning_rates = [0.01, 0.001]\n",
    "\n",
    "# Function to create and compile a model\n",
    "def create_model(layer_config, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_config[0], activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    for units in layer_config[1:]:\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate models with different configurations\n",
    "for layer_config in layer_configurations:\n",
    "    for learning_rate in learning_rates:\n",
    "        print(f\"Training model with layers {layer_config} and learning rate {learning_rate}\")\n",
    "        model = create_model(layer_config, learning_rate)\n",
    "        history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "        test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "        print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "        print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
