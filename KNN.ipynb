{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (58800, 15)\n",
      "y_train shape: (58800, 46)\n",
      "X_test shape: (14700, 15)\n",
      "y_test shape: (14700, 46)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0521 - loss: 3.5869 - val_accuracy: 0.0937 - val_loss: 3.2567\n",
      "Epoch 2/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0841 - loss: 3.2590 - val_accuracy: 0.1115 - val_loss: 3.0855\n",
      "Epoch 3/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1027 - loss: 3.1013 - val_accuracy: 0.1163 - val_loss: 2.9855\n",
      "Epoch 4/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1126 - loss: 3.0171 - val_accuracy: 0.1302 - val_loss: 2.9077\n",
      "Epoch 5/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1219 - loss: 2.9476 - val_accuracy: 0.1458 - val_loss: 2.8444\n",
      "Epoch 6/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1308 - loss: 2.8919 - val_accuracy: 0.1578 - val_loss: 2.7907\n",
      "Epoch 7/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1387 - loss: 2.8588 - val_accuracy: 0.1647 - val_loss: 2.7402\n",
      "Epoch 8/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1430 - loss: 2.8175 - val_accuracy: 0.1685 - val_loss: 2.6990\n",
      "Epoch 9/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1553 - loss: 2.7816 - val_accuracy: 0.1839 - val_loss: 2.6623\n",
      "Epoch 10/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1622 - loss: 2.7484 - val_accuracy: 0.1871 - val_loss: 2.6510\n",
      "Epoch 11/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1622 - loss: 2.7328 - val_accuracy: 0.1997 - val_loss: 2.6069\n",
      "Epoch 12/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1716 - loss: 2.7036 - val_accuracy: 0.2076 - val_loss: 2.5750\n",
      "Epoch 13/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1742 - loss: 2.6865 - val_accuracy: 0.2152 - val_loss: 2.5444\n",
      "Epoch 14/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1767 - loss: 2.6676 - val_accuracy: 0.2111 - val_loss: 2.5213\n",
      "Epoch 15/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1778 - loss: 2.6423 - val_accuracy: 0.2220 - val_loss: 2.5118\n",
      "Epoch 16/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1866 - loss: 2.6326 - val_accuracy: 0.2225 - val_loss: 2.5043\n",
      "Epoch 17/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1887 - loss: 2.6054 - val_accuracy: 0.2240 - val_loss: 2.4725\n",
      "Epoch 18/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1882 - loss: 2.6069 - val_accuracy: 0.2323 - val_loss: 2.4448\n",
      "Epoch 19/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1946 - loss: 2.5851 - val_accuracy: 0.2469 - val_loss: 2.4325\n",
      "Epoch 20/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1979 - loss: 2.5668 - val_accuracy: 0.2497 - val_loss: 2.4094\n",
      "Epoch 21/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2006 - loss: 2.5619 - val_accuracy: 0.2508 - val_loss: 2.3875\n",
      "Epoch 22/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.2008 - loss: 2.5622 - val_accuracy: 0.2502 - val_loss: 2.3848\n",
      "Epoch 23/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2028 - loss: 2.5490 - val_accuracy: 0.2651 - val_loss: 2.3713\n",
      "Epoch 24/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2059 - loss: 2.5284 - val_accuracy: 0.2639 - val_loss: 2.3630\n",
      "Epoch 25/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2144 - loss: 2.5119 - val_accuracy: 0.2624 - val_loss: 2.3558\n",
      "Epoch 26/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2170 - loss: 2.4964 - val_accuracy: 0.2722 - val_loss: 2.3163\n",
      "Epoch 27/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2178 - loss: 2.4923 - val_accuracy: 0.2693 - val_loss: 2.3406\n",
      "Epoch 28/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2158 - loss: 2.4878 - val_accuracy: 0.2683 - val_loss: 2.3228\n",
      "Epoch 29/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2205 - loss: 2.4803 - val_accuracy: 0.2823 - val_loss: 2.2890\n",
      "Epoch 30/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2230 - loss: 2.4730 - val_accuracy: 0.2901 - val_loss: 2.2815\n",
      "Epoch 31/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2243 - loss: 2.4717 - val_accuracy: 0.2826 - val_loss: 2.2773\n",
      "Epoch 32/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2267 - loss: 2.4552 - val_accuracy: 0.2849 - val_loss: 2.2621\n",
      "Epoch 33/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2256 - loss: 2.4546 - val_accuracy: 0.2912 - val_loss: 2.2672\n",
      "Epoch 34/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2292 - loss: 2.4428 - val_accuracy: 0.2917 - val_loss: 2.2557\n",
      "Epoch 35/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2324 - loss: 2.4359 - val_accuracy: 0.3034 - val_loss: 2.2268\n",
      "Epoch 36/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2354 - loss: 2.4277 - val_accuracy: 0.2999 - val_loss: 2.2402\n",
      "Epoch 37/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2361 - loss: 2.4242 - val_accuracy: 0.2953 - val_loss: 2.2413\n",
      "Epoch 38/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2344 - loss: 2.4184 - val_accuracy: 0.3027 - val_loss: 2.2236\n",
      "Epoch 39/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2384 - loss: 2.4170 - val_accuracy: 0.3190 - val_loss: 2.2020\n",
      "Epoch 40/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2385 - loss: 2.4100 - val_accuracy: 0.3115 - val_loss: 2.1949\n",
      "Epoch 41/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2361 - loss: 2.4148 - val_accuracy: 0.3149 - val_loss: 2.1823\n",
      "Epoch 42/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2395 - loss: 2.4019 - val_accuracy: 0.3077 - val_loss: 2.2126\n",
      "Epoch 43/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2446 - loss: 2.4016 - val_accuracy: 0.3065 - val_loss: 2.1944\n",
      "Epoch 44/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2508 - loss: 2.3750 - val_accuracy: 0.3187 - val_loss: 2.1660\n",
      "Epoch 45/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2484 - loss: 2.3872 - val_accuracy: 0.3256 - val_loss: 2.1656\n",
      "Epoch 46/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2445 - loss: 2.3769 - val_accuracy: 0.3161 - val_loss: 2.1871\n",
      "Epoch 47/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2449 - loss: 2.3776 - val_accuracy: 0.3270 - val_loss: 2.1466\n",
      "Epoch 48/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2524 - loss: 2.3695 - val_accuracy: 0.3208 - val_loss: 2.1435\n",
      "Epoch 49/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2500 - loss: 2.3700 - val_accuracy: 0.3206 - val_loss: 2.1517\n",
      "Epoch 50/50\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2527 - loss: 2.3552 - val_accuracy: 0.3253 - val_loss: 2.1232\n",
      "460/460 - 1s - 2ms/step - accuracy: 0.3252 - loss: 2.1245\n",
      "Test Accuracy: 32.52%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming X and y are your features and labels\n",
    "# X = ...\n",
    "# y = ...\n",
    "\n",
    "# Encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure y_train and y_test are one-hot encoded\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Define the Deep Learning model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # First hidden layer\n",
    "    Dropout(0.3),  # Dropout for regularization\n",
    "    Dense(64, activation='relu'),  # Second hidden layer\n",
    "    Dropout(0.3),  # Dropout for regularization\n",
    "    Dense(num_classes, activation='softmax')  # Output layer (num_classes classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Suitable for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,  # You can adjust the number of epochs\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)  # Use 20% of training data for validation\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# If you want to save the model after training:\n",
    "# model.save('your_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (58800, 15)\n",
      "y_train shape: (58800, 46)\n",
      "X_test shape: (14700, 15)\n",
      "y_test shape: (14700, 46)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.0481 - loss: 3.5851 - val_accuracy: 0.0904 - val_loss: 3.1620\n",
      "Epoch 2/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0883 - loss: 3.1747 - val_accuracy: 0.1026 - val_loss: 2.9883\n",
      "Epoch 3/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1072 - loss: 3.0174 - val_accuracy: 0.1227 - val_loss: 2.8893\n",
      "Epoch 4/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.1170 - loss: 2.9420 - val_accuracy: 0.1389 - val_loss: 2.8261\n",
      "Epoch 5/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1293 - loss: 2.8826 - val_accuracy: 0.1457 - val_loss: 2.7666\n",
      "Epoch 6/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1371 - loss: 2.8350 - val_accuracy: 0.1679 - val_loss: 2.7121\n",
      "Epoch 7/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1445 - loss: 2.7978 - val_accuracy: 0.1780 - val_loss: 2.6654\n",
      "Epoch 8/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1505 - loss: 2.7734 - val_accuracy: 0.1760 - val_loss: 2.6363\n",
      "Epoch 9/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1598 - loss: 2.7370 - val_accuracy: 0.1899 - val_loss: 2.6069\n",
      "Epoch 10/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.1662 - loss: 2.7059 - val_accuracy: 0.1985 - val_loss: 2.5531\n",
      "Epoch 11/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1692 - loss: 2.6855 - val_accuracy: 0.2056 - val_loss: 2.5296\n",
      "Epoch 12/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1745 - loss: 2.6726 - val_accuracy: 0.2130 - val_loss: 2.5123\n",
      "Epoch 13/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1789 - loss: 2.6518 - val_accuracy: 0.2177 - val_loss: 2.4946\n",
      "Epoch 14/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1817 - loss: 2.6244 - val_accuracy: 0.2264 - val_loss: 2.4521\n",
      "Epoch 15/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1875 - loss: 2.6070 - val_accuracy: 0.2373 - val_loss: 2.4339\n",
      "Epoch 16/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1900 - loss: 2.5925 - val_accuracy: 0.2361 - val_loss: 2.4134\n",
      "Epoch 17/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1934 - loss: 2.5903 - val_accuracy: 0.2234 - val_loss: 2.4279\n",
      "Epoch 18/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1957 - loss: 2.5667 - val_accuracy: 0.2342 - val_loss: 2.3831\n",
      "Epoch 19/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.2017 - loss: 2.5495 - val_accuracy: 0.2509 - val_loss: 2.3663\n",
      "Epoch 20/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.2025 - loss: 2.5381 - val_accuracy: 0.2634 - val_loss: 2.3191\n",
      "Epoch 21/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.2010 - loss: 2.5302 - val_accuracy: 0.2695 - val_loss: 2.3120\n",
      "Epoch 22/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2056 - loss: 2.5157 - val_accuracy: 0.2663 - val_loss: 2.2916\n",
      "Epoch 23/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2095 - loss: 2.5062 - val_accuracy: 0.2700 - val_loss: 2.2858\n",
      "Epoch 24/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2138 - loss: 2.4922 - val_accuracy: 0.2645 - val_loss: 2.2892\n",
      "Epoch 25/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2141 - loss: 2.4832 - val_accuracy: 0.2859 - val_loss: 2.2642\n",
      "Epoch 26/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2137 - loss: 2.4931 - val_accuracy: 0.2863 - val_loss: 2.2487\n",
      "Epoch 27/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2186 - loss: 2.4770 - val_accuracy: 0.2770 - val_loss: 2.2404\n",
      "Epoch 28/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.2161 - loss: 2.4693 - val_accuracy: 0.2672 - val_loss: 2.2671\n",
      "Epoch 29/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2213 - loss: 2.4546 - val_accuracy: 0.2958 - val_loss: 2.2279\n",
      "Epoch 30/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2198 - loss: 2.4600 - val_accuracy: 0.2981 - val_loss: 2.1859\n",
      "Epoch 31/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2271 - loss: 2.4421 - val_accuracy: 0.2987 - val_loss: 2.1922\n",
      "Epoch 32/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2239 - loss: 2.4451 - val_accuracy: 0.3080 - val_loss: 2.1936\n",
      "Epoch 33/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2266 - loss: 2.4338 - val_accuracy: 0.3027 - val_loss: 2.1968\n",
      "Epoch 34/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2241 - loss: 2.4360 - val_accuracy: 0.3077 - val_loss: 2.1691\n",
      "Epoch 35/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2284 - loss: 2.4156 - val_accuracy: 0.3124 - val_loss: 2.1643\n",
      "Epoch 36/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2297 - loss: 2.4177 - val_accuracy: 0.3227 - val_loss: 2.1486\n",
      "Epoch 37/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2344 - loss: 2.4085 - val_accuracy: 0.3196 - val_loss: 2.1340\n",
      "Epoch 38/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2348 - loss: 2.4113 - val_accuracy: 0.3170 - val_loss: 2.1389\n",
      "Epoch 39/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2349 - loss: 2.4058 - val_accuracy: 0.3156 - val_loss: 2.1335\n",
      "Epoch 40/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2342 - loss: 2.3997 - val_accuracy: 0.3107 - val_loss: 2.1433\n",
      "Epoch 41/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2350 - loss: 2.3931 - val_accuracy: 0.3349 - val_loss: 2.0993\n",
      "Epoch 42/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2422 - loss: 2.3773 - val_accuracy: 0.3271 - val_loss: 2.1078\n",
      "Epoch 43/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.2401 - loss: 2.3891 - val_accuracy: 0.3321 - val_loss: 2.0969\n",
      "Epoch 44/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2399 - loss: 2.3843 - val_accuracy: 0.3164 - val_loss: 2.1210\n",
      "Epoch 45/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2376 - loss: 2.3827 - val_accuracy: 0.3245 - val_loss: 2.0952\n",
      "Epoch 46/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2429 - loss: 2.3744 - val_accuracy: 0.3321 - val_loss: 2.0934\n",
      "Epoch 47/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2436 - loss: 2.3636 - val_accuracy: 0.3264 - val_loss: 2.0858\n",
      "Epoch 48/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2465 - loss: 2.3687 - val_accuracy: 0.3196 - val_loss: 2.1007\n",
      "Epoch 49/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2424 - loss: 2.3684 - val_accuracy: 0.3388 - val_loss: 2.0814\n",
      "Epoch 50/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2447 - loss: 2.3686 - val_accuracy: 0.3486 - val_loss: 2.0706\n",
      "Epoch 51/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.2405 - loss: 2.3714 - val_accuracy: 0.3406 - val_loss: 2.0823\n",
      "Epoch 52/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.2476 - loss: 2.3498 - val_accuracy: 0.3363 - val_loss: 2.0820\n",
      "Epoch 53/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2491 - loss: 2.3504 - val_accuracy: 0.3463 - val_loss: 2.0695\n",
      "Epoch 54/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2497 - loss: 2.3368 - val_accuracy: 0.3401 - val_loss: 2.0468\n",
      "Epoch 55/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2513 - loss: 2.3535 - val_accuracy: 0.3444 - val_loss: 2.0354\n",
      "Epoch 56/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2530 - loss: 2.3374 - val_accuracy: 0.3569 - val_loss: 2.0414\n",
      "Epoch 57/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2542 - loss: 2.3322 - val_accuracy: 0.3559 - val_loss: 2.0500\n",
      "Epoch 58/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2532 - loss: 2.3310 - val_accuracy: 0.3426 - val_loss: 2.0482\n",
      "Epoch 59/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2522 - loss: 2.3355 - val_accuracy: 0.3596 - val_loss: 2.0212\n",
      "Epoch 60/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2554 - loss: 2.3316 - val_accuracy: 0.3454 - val_loss: 2.0411\n",
      "Epoch 61/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2520 - loss: 2.3350 - val_accuracy: 0.3396 - val_loss: 2.0509\n",
      "Epoch 62/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2561 - loss: 2.3276 - val_accuracy: 0.3412 - val_loss: 2.0491\n",
      "Epoch 63/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2546 - loss: 2.3329 - val_accuracy: 0.3532 - val_loss: 2.0208\n",
      "Epoch 64/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2521 - loss: 2.3319 - val_accuracy: 0.3616 - val_loss: 2.0208\n",
      "Epoch 65/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2559 - loss: 2.3231 - val_accuracy: 0.3440 - val_loss: 2.0364\n",
      "Epoch 66/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2556 - loss: 2.3169 - val_accuracy: 0.3644 - val_loss: 2.0009\n",
      "Epoch 67/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2618 - loss: 2.3127 - val_accuracy: 0.3610 - val_loss: 1.9947\n",
      "Epoch 68/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2573 - loss: 2.3198 - val_accuracy: 0.3539 - val_loss: 2.0110\n",
      "Epoch 69/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.2586 - loss: 2.3111 - val_accuracy: 0.3611 - val_loss: 2.0189\n",
      "Epoch 70/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2612 - loss: 2.3083 - val_accuracy: 0.3693 - val_loss: 1.9969\n",
      "Epoch 71/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.2640 - loss: 2.2991 - val_accuracy: 0.3776 - val_loss: 1.9746\n",
      "Epoch 72/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2669 - loss: 2.2969 - val_accuracy: 0.3590 - val_loss: 2.0038\n",
      "Epoch 73/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2612 - loss: 2.3181 - val_accuracy: 0.3769 - val_loss: 1.9864\n",
      "Epoch 74/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2589 - loss: 2.3039 - val_accuracy: 0.3507 - val_loss: 2.0227\n",
      "Epoch 75/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2561 - loss: 2.3223 - val_accuracy: 0.3677 - val_loss: 1.9851\n",
      "Epoch 76/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2622 - loss: 2.2927 - val_accuracy: 0.3732 - val_loss: 1.9887\n",
      "Epoch 77/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2619 - loss: 2.2998 - val_accuracy: 0.3630 - val_loss: 1.9749\n",
      "Epoch 78/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2649 - loss: 2.2991 - val_accuracy: 0.3599 - val_loss: 2.0054\n",
      "Epoch 79/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2643 - loss: 2.2911 - val_accuracy: 0.3784 - val_loss: 1.9504\n",
      "Epoch 80/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2636 - loss: 2.2991 - val_accuracy: 0.3745 - val_loss: 1.9392\n",
      "Epoch 81/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2641 - loss: 2.2983 - val_accuracy: 0.3737 - val_loss: 1.9671\n",
      "Epoch 82/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2698 - loss: 2.2824 - val_accuracy: 0.3822 - val_loss: 1.9653\n",
      "Epoch 83/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2689 - loss: 2.2768 - val_accuracy: 0.3696 - val_loss: 1.9658\n",
      "Epoch 84/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.2690 - loss: 2.2753 - val_accuracy: 0.3746 - val_loss: 1.9558\n",
      "Epoch 85/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.2641 - loss: 2.2866 - val_accuracy: 0.3741 - val_loss: 1.9515\n",
      "Epoch 86/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2636 - loss: 2.2787 - val_accuracy: 0.3853 - val_loss: 1.9615\n",
      "Epoch 87/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2707 - loss: 2.2708 - val_accuracy: 0.3838 - val_loss: 1.9406\n",
      "Epoch 88/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2662 - loss: 2.2726 - val_accuracy: 0.3631 - val_loss: 1.9686\n",
      "Epoch 89/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2691 - loss: 2.2729 - val_accuracy: 0.3741 - val_loss: 1.9559\n",
      "Epoch 90/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2712 - loss: 2.2785 - val_accuracy: 0.3851 - val_loss: 1.9590\n",
      "Epoch 91/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2699 - loss: 2.2716 - val_accuracy: 0.3955 - val_loss: 1.9215\n",
      "Epoch 92/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2721 - loss: 2.2681 - val_accuracy: 0.3781 - val_loss: 1.9550\n",
      "Epoch 93/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2699 - loss: 2.2637 - val_accuracy: 0.3884 - val_loss: 1.9638\n",
      "Epoch 94/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2682 - loss: 2.2808 - val_accuracy: 0.3846 - val_loss: 1.9423\n",
      "Epoch 95/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2685 - loss: 2.2836 - val_accuracy: 0.3692 - val_loss: 1.9629\n",
      "Epoch 96/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2661 - loss: 2.2729 - val_accuracy: 0.3838 - val_loss: 1.9445\n",
      "Epoch 97/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2700 - loss: 2.2723 - val_accuracy: 0.3808 - val_loss: 1.9335\n",
      "Epoch 98/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2694 - loss: 2.2561 - val_accuracy: 0.3846 - val_loss: 1.9496\n",
      "Epoch 99/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2702 - loss: 2.2661 - val_accuracy: 0.3721 - val_loss: 1.9466\n",
      "Epoch 100/100\n",
      "\u001b[1m1470/1470\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2712 - loss: 2.2618 - val_accuracy: 0.3914 - val_loss: 1.9140\n",
      "460/460 - 1s - 2ms/step - accuracy: 0.3965 - loss: 1.9011\n",
      "Test Accuracy: 39.65%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)), \n",
    "    Dropout(0.4),  \n",
    "    Dense(128, activation='relu'),  \n",
    "    Dropout(0.4),  \n",
    "    Dense(64, activation='relu'),  \n",
    "    Dropout(0.3),  \n",
    "    Dense(num_classes, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  \n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,  \n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)  \n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# model.save('your_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
