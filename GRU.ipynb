{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.0617 - loss: 3.1080 - val_accuracy: 0.0957 - val_loss: 2.9885\n",
      "Epoch 2/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.0881 - loss: 2.9927 - val_accuracy: 0.1065 - val_loss: 2.9213\n",
      "Epoch 3/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1063 - loss: 2.9271 - val_accuracy: 0.1201 - val_loss: 2.8643\n",
      "Epoch 4/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1190 - loss: 2.8835 - val_accuracy: 0.1374 - val_loss: 2.8153\n",
      "Epoch 5/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.1272 - loss: 2.8378 - val_accuracy: 0.1524 - val_loss: 2.7554\n",
      "Epoch 6/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1430 - loss: 2.7855 - val_accuracy: 0.1639 - val_loss: 2.7059\n",
      "Epoch 7/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1488 - loss: 2.7610 - val_accuracy: 0.1690 - val_loss: 2.6704\n",
      "Epoch 8/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1563 - loss: 2.7178 - val_accuracy: 0.1820 - val_loss: 2.6227\n",
      "Epoch 9/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1722 - loss: 2.6652 - val_accuracy: 0.1895 - val_loss: 2.5685\n",
      "Epoch 10/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1791 - loss: 2.6337 - val_accuracy: 0.2119 - val_loss: 2.5210\n",
      "Epoch 11/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1844 - loss: 2.5880 - val_accuracy: 0.2183 - val_loss: 2.4832\n",
      "Epoch 12/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1966 - loss: 2.5498 - val_accuracy: 0.2185 - val_loss: 2.4502\n",
      "Epoch 13/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2004 - loss: 2.5222 - val_accuracy: 0.2339 - val_loss: 2.3950\n",
      "Epoch 14/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.2060 - loss: 2.4999 - val_accuracy: 0.2430 - val_loss: 2.3848\n",
      "Epoch 15/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.2131 - loss: 2.4681 - val_accuracy: 0.2555 - val_loss: 2.3231\n",
      "Epoch 16/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.2219 - loss: 2.4463 - val_accuracy: 0.2571 - val_loss: 2.2994\n",
      "Epoch 17/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2274 - loss: 2.4267 - val_accuracy: 0.2773 - val_loss: 2.2619\n",
      "Epoch 18/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2366 - loss: 2.3973 - val_accuracy: 0.2761 - val_loss: 2.2536\n",
      "Epoch 19/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2315 - loss: 2.3867 - val_accuracy: 0.2733 - val_loss: 2.2437\n",
      "Epoch 20/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.2397 - loss: 2.3770 - val_accuracy: 0.2879 - val_loss: 2.2257\n",
      "Epoch 21/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2474 - loss: 2.3486 - val_accuracy: 0.3080 - val_loss: 2.1553\n",
      "Epoch 22/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2510 - loss: 2.3292 - val_accuracy: 0.2954 - val_loss: 2.1460\n",
      "Epoch 23/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2532 - loss: 2.3160 - val_accuracy: 0.2976 - val_loss: 2.1433\n",
      "Epoch 24/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2611 - loss: 2.2997 - val_accuracy: 0.3131 - val_loss: 2.0936\n",
      "Epoch 25/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2614 - loss: 2.2865 - val_accuracy: 0.3090 - val_loss: 2.1180\n",
      "Epoch 26/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2652 - loss: 2.2663 - val_accuracy: 0.3322 - val_loss: 2.0687\n",
      "Epoch 27/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2726 - loss: 2.2547 - val_accuracy: 0.3347 - val_loss: 2.0548\n",
      "Epoch 28/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2745 - loss: 2.2464 - val_accuracy: 0.3437 - val_loss: 2.0347\n",
      "Epoch 29/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2749 - loss: 2.2285 - val_accuracy: 0.3339 - val_loss: 2.0405\n",
      "Epoch 30/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.2758 - loss: 2.2314 - val_accuracy: 0.3388 - val_loss: 2.0087\n",
      "Epoch 31/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2808 - loss: 2.2011 - val_accuracy: 0.3516 - val_loss: 1.9908\n",
      "Epoch 32/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2907 - loss: 2.1953 - val_accuracy: 0.3519 - val_loss: 1.9636\n",
      "Epoch 33/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2815 - loss: 2.2066 - val_accuracy: 0.3570 - val_loss: 1.9557\n",
      "Epoch 34/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2904 - loss: 2.1815 - val_accuracy: 0.3565 - val_loss: 1.9566\n",
      "Epoch 35/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2916 - loss: 2.1745 - val_accuracy: 0.3726 - val_loss: 1.9318\n",
      "Epoch 36/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2948 - loss: 2.1619 - val_accuracy: 0.3744 - val_loss: 1.9332\n",
      "Epoch 37/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2898 - loss: 2.1592 - val_accuracy: 0.3709 - val_loss: 1.9261\n",
      "Epoch 38/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3003 - loss: 2.1470 - val_accuracy: 0.3749 - val_loss: 1.9143\n",
      "Epoch 39/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2989 - loss: 2.1423 - val_accuracy: 0.3706 - val_loss: 1.8944\n",
      "Epoch 40/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3014 - loss: 2.1461 - val_accuracy: 0.3814 - val_loss: 1.9080\n",
      "Epoch 41/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3054 - loss: 2.1323 - val_accuracy: 0.3755 - val_loss: 1.9136\n",
      "Epoch 42/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.3051 - loss: 2.1158 - val_accuracy: 0.3787 - val_loss: 1.8965\n",
      "Epoch 43/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.3063 - loss: 2.1135 - val_accuracy: 0.3822 - val_loss: 1.8885\n",
      "Epoch 44/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3087 - loss: 2.1030 - val_accuracy: 0.3877 - val_loss: 1.8717\n",
      "Epoch 45/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3147 - loss: 2.0935 - val_accuracy: 0.3774 - val_loss: 1.8651\n",
      "Epoch 46/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3075 - loss: 2.0893 - val_accuracy: 0.3870 - val_loss: 1.8554\n",
      "Epoch 47/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3128 - loss: 2.0852 - val_accuracy: 0.3955 - val_loss: 1.8217\n",
      "Epoch 48/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3147 - loss: 2.0835 - val_accuracy: 0.4015 - val_loss: 1.8206\n",
      "Epoch 49/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3167 - loss: 2.0720 - val_accuracy: 0.4138 - val_loss: 1.8017\n",
      "Epoch 50/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3151 - loss: 2.0694 - val_accuracy: 0.4151 - val_loss: 1.7892\n",
      "Epoch 51/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3248 - loss: 2.0579 - val_accuracy: 0.4164 - val_loss: 1.7808\n",
      "Epoch 52/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3180 - loss: 2.0643 - val_accuracy: 0.4179 - val_loss: 1.7724\n",
      "Epoch 53/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3270 - loss: 2.0421 - val_accuracy: 0.4112 - val_loss: 1.7764\n",
      "Epoch 54/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3266 - loss: 2.0455 - val_accuracy: 0.4090 - val_loss: 1.7780\n",
      "Epoch 55/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3289 - loss: 2.0306 - val_accuracy: 0.4236 - val_loss: 1.7618\n",
      "Epoch 56/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.3293 - loss: 2.0280 - val_accuracy: 0.4321 - val_loss: 1.7407\n",
      "Epoch 57/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3313 - loss: 2.0223 - val_accuracy: 0.4190 - val_loss: 1.7581\n",
      "Epoch 58/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3329 - loss: 2.0240 - val_accuracy: 0.4224 - val_loss: 1.7582\n",
      "Epoch 59/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3349 - loss: 2.0090 - val_accuracy: 0.4300 - val_loss: 1.7284\n",
      "Epoch 60/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3391 - loss: 2.0119 - val_accuracy: 0.4320 - val_loss: 1.7311\n",
      "Epoch 61/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3384 - loss: 2.0181 - val_accuracy: 0.4228 - val_loss: 1.7224\n",
      "Epoch 62/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3365 - loss: 1.9972 - val_accuracy: 0.4334 - val_loss: 1.7092\n",
      "Epoch 63/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3382 - loss: 1.9883 - val_accuracy: 0.4287 - val_loss: 1.7302\n",
      "Epoch 64/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3436 - loss: 1.9856 - val_accuracy: 0.4397 - val_loss: 1.7089\n",
      "Epoch 65/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3400 - loss: 1.9813 - val_accuracy: 0.4328 - val_loss: 1.7268\n",
      "Epoch 66/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3517 - loss: 1.9699 - val_accuracy: 0.4286 - val_loss: 1.7418\n",
      "Epoch 67/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3391 - loss: 1.9837 - val_accuracy: 0.4439 - val_loss: 1.6748\n",
      "Epoch 68/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3418 - loss: 1.9925 - val_accuracy: 0.4396 - val_loss: 1.6964\n",
      "Epoch 69/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3474 - loss: 1.9702 - val_accuracy: 0.4425 - val_loss: 1.6715\n",
      "Epoch 70/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3445 - loss: 1.9773 - val_accuracy: 0.4424 - val_loss: 1.6829\n",
      "Epoch 71/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3438 - loss: 1.9684 - val_accuracy: 0.4526 - val_loss: 1.6592\n",
      "Epoch 72/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3433 - loss: 1.9724 - val_accuracy: 0.4394 - val_loss: 1.6669\n",
      "Epoch 73/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3493 - loss: 1.9495 - val_accuracy: 0.4572 - val_loss: 1.6639\n",
      "Epoch 74/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3510 - loss: 1.9502 - val_accuracy: 0.4578 - val_loss: 1.6350\n",
      "Epoch 75/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3495 - loss: 1.9530 - val_accuracy: 0.4619 - val_loss: 1.6363\n",
      "Epoch 76/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3570 - loss: 1.9449 - val_accuracy: 0.4620 - val_loss: 1.6194\n",
      "Epoch 77/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3581 - loss: 1.9344 - val_accuracy: 0.4606 - val_loss: 1.6461\n",
      "Epoch 78/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3598 - loss: 1.9246 - val_accuracy: 0.4556 - val_loss: 1.6432\n",
      "Epoch 79/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3554 - loss: 1.9451 - val_accuracy: 0.4751 - val_loss: 1.6074\n",
      "Epoch 80/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3622 - loss: 1.9186 - val_accuracy: 0.4564 - val_loss: 1.6523\n",
      "Epoch 81/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3616 - loss: 1.9171 - val_accuracy: 0.4584 - val_loss: 1.6380\n",
      "Epoch 82/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.3627 - loss: 1.9189 - val_accuracy: 0.4770 - val_loss: 1.5907\n",
      "Epoch 83/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3677 - loss: 1.9139 - val_accuracy: 0.4664 - val_loss: 1.6143\n",
      "Epoch 84/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3611 - loss: 1.9146 - val_accuracy: 0.4798 - val_loss: 1.5923\n",
      "Epoch 85/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3707 - loss: 1.8955 - val_accuracy: 0.4763 - val_loss: 1.5965\n",
      "Epoch 86/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.3678 - loss: 1.9069 - val_accuracy: 0.4882 - val_loss: 1.5703\n",
      "Epoch 87/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.3648 - loss: 1.8996 - val_accuracy: 0.4779 - val_loss: 1.5874\n",
      "Epoch 88/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.3722 - loss: 1.8917 - val_accuracy: 0.4532 - val_loss: 1.6483\n",
      "Epoch 89/100\n",
      "\u001b[1m1190/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.3711 - loss: 1.8823 - val_accuracy: 0.4870 - val_loss: 1.5507\n",
      "Epoch 90/100\n",
      "\u001b[1m1182/1190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3686 - loss: 1.8894"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('corrected_data.csv')\n",
    "\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "model = Sequential([\n",
    "    GRU(128, activation='tanh', return_sequences=True, input_shape=(1, X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    GRU(64, activation='tanh'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2, \n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "final_accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Final Accuracy: {final_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('corrected_data.csv')\n",
    "\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "model = Sequential([\n",
    "    GRU(128, activation='tanh', return_sequences=True, input_shape=(1, X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    GRU(64, activation='tanh'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2, \n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "final_accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Final Accuracy: {final_accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
